<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Unified 3D Gaussian Splatting for Motion and Defocus Blur Reconstruction</title>
  <meta name="description" content="Unified 3D Gaussian Splatting for Motion and Defocus Blur Reconstruction â€“ Project Page" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" rel="stylesheet" />
  <style>
    :root { --brand:#2563eb; --ink:#1f2328; --muted:#66707b; }
    html,body { font-family: 'Inter', system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; color: var(--ink); }
    
    /* Hero */
    .hero.is-brand { background: linear-gradient(180deg, #f0f6ff 0%, #ffffff 100%); padding-top: 3rem; padding-bottom: 3rem; }

    /* Titles & text */
    .publication-title { font-weight: 800; letter-spacing: -0.02em; margin-bottom: 2.2rem; font-size: 2.8rem; }
    .subtitle.lead { color: var(--muted); margin-bottom: 1rem; font-size: 1.5rem; }
    .author-list { font-size: 1.2rem; font-weight: 500; margin-bottom: 0.5rem; }
    .affiliation { font-size: 1rem; color: var(--muted); margin-bottom: 1rem; }

    /* Card */
    .cardish { background:#fff; border-radius:12px; box-shadow:0 4px 16px rgba(31,35,40,0.08); padding:1.5rem; margin-bottom:1rem; }
    .content img, .content video { border-radius:12px; }
    .cardish img {
      display: block;
      margin-bottom: 0 !important;
    }

    /* Section spacing */
    .section { padding-top: 1rem !important; padding-bottom: 1rem !important; }

    /* Section title */
    .section-title { font-weight:800; font-size: 1.6rem; margin-bottom: 0.75rem; }

    /* Videos */
    .video-list { display: flex; flex-direction: column; gap: 20px; margin-top: 1rem; }

    /* Capsule links */
    .capsule-links { margin-top:1rem; }
    .capsule-links a {
      display:inline-block;
      margin:0 .4rem .4rem 0;
      padding:.6rem 1.2rem;
      border-radius:999px;
      font-weight:600;
      font-size:1rem;
      background:var(--brand);
      color:#fff;
      border:1px solid var(--brand);
      transition: background .2s, transform .2s;
    }
    .capsule-links a:hover { background:#1d4ed8; transform: translateY(-1px); }

    /* Teaser figure spacing */
    .cardish img + p { margin-top: 0.1rem; font-size:1.15rem; }

    .footer { color:#8a939f; margin-top: 2rem; }

    .image,
    figure.image {
      margin-bottom: 0 !important;
    }

    .cardish .image,
    .cardish figure.image {
      margin-top: 0.5rem;
    }

    .cardish .section-title + p {
      text-align: justify;
    }
  </style>
</head>
<body>

  <!-- Title Block -->
  <section class="hero is-brand">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
        <h1 class="title publication-title">Unified 3D Gaussian Splatting for Motion and Defocus Blur Reconstruction</h1>
        <p class="subtitle lead">CAD/Graphics 2025 & Visual Informatics paper.</p>
        <p class="author-list">Li Liu, Jing Duan, Xiaodong Fu, Wei Peng, Lijun Liu</p>
        <p class="affiliation">Kunming University of Science and Technology</p>

        <div class="capsule-links">
          <a href="https://github.com/sunbeam-217/Dual-blur-reconstruction" target="_blank">Code</a>
          <a href="https://arxiv.org/abs/xxxx.xxxxx" target="_blank">Paper</a>
          <a href="https://dataset-link.com" target="_blank">Dataset</a>
        </div>
      </div>
    </div>
  </section>

  <!-- Intro Figure and Teaser Text -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content has-text-centered">
        <figure class="image">
          <img src="https://sunbeam-217.oss-cn-chengdu.aliyuncs.com/img/202508190018102.png" alt="Teaser figure" />
        </figure>
        <p>
          Given a set of multi-view blurry images containing both motion and defocus blur, our method can reconstruct a high-quality sharp 3D scene representation.
        </p>
      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">Abstract</h2>
        <p style="text-align: justify; font-size:1rem;">
          This paper proposes a unified 3D Gaussian splatting framework consisting of three key
          components for motion and defocus blur reconstruction. First, a dual-blur perception
          module is designed to generate pixel-wise masks and predict the types of motion and
          defocus blur, guiding structural feature extraction. Second, a blur-aware Gaussian splat-
          ting integrates blur-aware features into the splatting process for accurate modeling of the
          global and local scene structure. Third, an Unoptimized Gaussian Ratio (UGR)-opacity
          joint optimization strategy is proposed to refine under-optimized regions, improving
          reconstruction accuracy under complex blur conditions. Experiments on a newly con-
          structed motion and defocus blur dataset demonstrate the effectiveness of the proposed
          method for novel view synthesis. Compared with state-of-the-art methods, our frame-
          work achieves improvements of 0.28 dB, 2.46% and 39.88% on PSNR, SSIM, and
          LPIPS, respectively. For deblurring tasks, it achieves improvements of 0.36 dB, 3.24%
          and 28.96% on on the same metrics. These results highlight the robustness and effec-
          tiveness of this approach.
        </p>
      </div>
    </div>
  </section>

  <!-- Keywords -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">Keywords</h2>
        <p>3D Gaussian Splatting, blur reconstruction, dual-blur perception, blur-aware feature, Joint optimization</p>
      </div>
    </div>
  </section>

  <!-- Method Overview -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">Method Overview</h2>
        <p>Our three-stage framework consists of dual-blur perception, blur-aware Gaussian splatting, and joint UGR-opacity optimization. Given a sequence
          of dual-blur images, the dual-blur perception module generates pixel-wise blur masks for each image. Blur-aware Gaussian splatting applies the masks
          to both input and rendered images to jointly optimize the 3D Gaussians and camera poses. The UGR-opacity optimization strategy adaptively increases
          updates in under-optimized masked regions. The final output is a clear 3D scene reconstruction.</p>
        <figure class="image">
          <img src="https://sunbeam-217.oss-cn-chengdu.aliyuncs.com/img/202506261356962.png" alt="Pipeline overview" />
        </figure>
      </div>
    </div>
  </section>

  <!-- Results -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">Rendering Results</h2>
        <p>Left: video renderings produced by our method; Right: input images</p>
        <div class="video-list">
          <video src="https://github.com/user-attachments/assets/377de659-3e9f-47ed-b9f6-5821fefa944d" controls></video>
          <video src="https://github.com/user-attachments/assets/86f79308-6970-49d7-8d1f-e2954600b49b" controls></video>
          <video src="https://github.com/user-attachments/assets/75e338ee-7c7e-4935-a1e8-60910ea7ee13" controls></video>
          <video src="https://github.com/user-attachments/assets/0158289b-1163-4f98-b1b4-054e9f72fff1" controls></video>
          <video src="https://github.com/user-attachments/assets/c40cb281-be34-410c-abac-1bda991e4bc1" controls></video>
        </div>
      </div>
    </div>
  </section>

  <!-- Limitations -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">Limitations</h2>
        <ul style="text-align: justify;">
          <li>Performance drops in regions with severe local blur.</li>
          <li>Linear camera motion modeling limits accuracy for complex trajectories.</li>
          <li>Cannot handle per-pixel mixed-blur types (e.g., the entanglement of motion and defocus blur).</li>
        </ul>
      </div>
    </div>
  </section>

  <!-- Acknowledgements -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">Acknowledgements</h2>
        <p>We thank the anonymous reviewers for their valuable feedback.</p>
      </div>
    </div>
  </section>

  <!-- References -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="cardish content">
        <h2 class="title section-title">References</h2>
        <p>[Placeholder for formatted references]</p>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer has-text-centered">
    <div class="container is-max-desktop">
      <p>&copy; 2025 Unified 3D Gaussian Splatting. All rights reserved.</p>
    </div>
  </footer>
</body>
</html>
